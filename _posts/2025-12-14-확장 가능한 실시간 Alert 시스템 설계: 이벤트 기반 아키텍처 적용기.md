---
title: "Lateral Join으로 쿼리 개선하기"
date: 2025-12-17 00:00:00 +/- TTTT
categories: [트러블 슈팅]
tags: [postgresql, performance]	# TAG는 반드시 소문자로 이루어져야함!
image: /assets/img/2025-10-21/img0.png
published: false

---
<style>
  figcaption {
    font-size: 14px;
    color: #555;
    font-style: italic;
  }
</style>



> *Lateral Join을 통해 성능을 개선 시킨 경험과 그 과정을 설명합니다. 민감할 수 있는 정보는 변경하거나 지웠음을 알립니다.*
---

## 배경
최근 회사에서, 운영하던 웹 모니터링 솔루션 중 특정 화면의 로딩이 매우 오래 걸리는 것을 발견했다. 페이지를 로딩하는데 거의 4~5초 정도 걸리는 듯 했다. 초반에는 이러지 않았지만, 데이터가 쌓이면서 API 응답 속도가 느려진 듯 하다. 


## 병목 지점 파악 
API 내부 동작은 cpu-burst 하진 않고, DB에서 읽어오는 일반적인 조회 기능을 가진 API 였기 때문에 DB쪽에서 데이터를 읽어 오면서 생긴 병목일 것이라고 예상했다.

### 쿼리 성능 측정
DB에서 병목이 되는 지점을 정확히 알기 위해서 slow query를 먼저 알고자 했다. DB에서도 직접 알 수 있겠지만 해당 프로젝트는 Nest.js + TypeORM을 사용하고 있기 떄문에 TypeORM의 Data Source Options를 이용하여 서버 로그에서 쿼리 성능에 대한 정보를 보고자 했다.


```typescript
export const databaseConfig: TypeOrmModuleOptions = {
  ...
  logger: 'advanced-console',
  maxQueryExecutionTime: 1000,
  ...
}
```
쿼리에 대한 실행 시간 정보까지 알 수 있는 `'advanced-console'`를 logger로 설정하고(디폴트 옵션이라 설정 생략 가능) maxQueryExcutionTime 값을 `1000(ms)`으로 두면 1초 이상이 걸리는 slow 쿼리에 대해 기록한다.

```
query is slow: 
      SELECT DISTINCT ON (data.facility_metric_id)
       ...
        data.labels
      FROM facility_metric_data data
      JOIN facility_metric_definitions def ON data.facility_metric_id = def.id
      WHERE data.facility_id = $1
        AND def.facility_type = $2
      ORDER BY data.facility_metric_id, data.measured_dt DESC
    -- PARAMETERS: ["29","CRAC"]
execution time: 2338
```
특정 장비에 대해서 수집되는 메트릭에 대해서 최근 값 1개만 가지고 오는 쿼리이다.
Distnct on 과 join 


### 데이터 확인
유독 id가 28, 29인 대상에 대해서 성능 저하가 발생하여 데이터를 확인해보았다.

```sql
SELECT facility_id, COUNT(*) 
FROM facility_metric_data 
WHERE facility_id IS NOT NULL 
GROUP BY facility_id;


facility_id | count
------------|----------
28          | 1,163,550  ← CRAC, 매우 많음!
29          | 1,040,604  ← CRAC, 매우 많음!
30          | 약 수천 개  (다른 facility 타입)
```
데이터가 많이 쌓인 것은 확인이 됐다. 이제 실제로 쿼리에서 이 데이터를 조회할 때 어떤 과정으로 조회하는지를 알아보자

### 실행 계획 확인
```sql
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT DISTINCT ON (data.facility_metric_id)
  data.facility_id        AS "facilityId",
  data.facility_metric_id AS "facilityMetricId",
  def.id                  AS "defId",
  def.name                AS "metricName",
  def.data_type           AS "dataType",
  def.unit,
  def.facility_type       AS "facilityType",
  def.description,
  data.value_num          AS "valueNum",
  data.value_int          AS "valueInt",
  data.value_bool         AS "valueBool",
  data.value_text         AS "valueText",
  data.value_json         AS "valueJson",
  data.measured_dt        AS "measuredDt",
  data.received_dt        AS "receivedDt",
  data.labels
FROM facility_metric_data data
JOIN facility_metric_definitions def
  ON data.facility_metric_id = def.id
WHERE data.facility_id = 29
  AND def.facility_type = 'CRAC'
ORDER BY data.facility_metric_id, data.measured_dt DESC;

# 결과
Unique  (cost=19128.82..249348.63 rows=13 width=551) (actual time=366.327..2319.447 rows=7 loops=1)
"  Output: data.facility_id, data.facility_metric_id, def.id, def.name, def.data_type, def.unit, def.facility_type, def.description, data.value_num, data.value_int, data.value_bool, data.value_text, data.value_json, data.measured_dt, data.received_dt, data.labels"
"  Buffers: shared hit=214138 read=707011, temp read=30459 written=30511"
  ->  Incremental Sort  (cost=19128.82..249235.21 rows=45371 width=551) (actual time=366.325..2273.731 rows=1040604 loops=1)
"        Output: data.facility_id, data.facility_metric_id, def.id, def.name, def.data_type, def.unit, def.facility_type, def.description, data.value_num, data.value_int, data.value_bool, data.value_text, data.value_json, data.measured_dt, data.received_dt, data.labels"
"        Sort Key: data.facility_metric_id, data.measured_dt DESC"
        Presorted Key: data.facility_metric_id
        Full-sort Groups: 7  Sort Method: quicksort  Average Memory: 54kB  Peak Memory: 54kB
        Pre-sorted Groups: 7  Sort Method: external merge  Average Disk: 66336kB  Peak Disk: 66336kB
"        Buffers: shared hit=214138 read=707011, temp read=30459 written=30511"
        ->  Nested Loop  (cost=0.57..245997.94 rows=45371 width=551) (actual time=0.096..1687.899 rows=1040604 loops=1)
"              Output: data.facility_id, data.facility_metric_id, def.id, def.name, def.data_type, def.unit, def.facility_type, def.description, data.value_num, data.value_int, data.value_bool, data.value_text, data.value_json, data.measured_dt, data.received_dt, data.labels"
              Buffers: shared hit=214135 read=707011
              ->  Index Scan using facility_metric_definitions_pkey on public.facility_metric_definitions def  (cost=0.14..12.56 rows=1 width=112) (actual time=0.031..0.045 rows=9 loops=1)
"                    Output: def.id, def.name, def.data_type, def.unit, def.description, def.created_at, def.updated_at, def.facility_type, def.attachment_type"
                    Filter: (def.facility_type = 'CRAC'::facility_type)
                    Rows Removed by Filter: 15
                    Buffers: shared hit=1 read=1
              ->  Index Scan using ix_fmd_facility_metric_time on public.facility_metric_data data  (cost=0.43..245147.75 rows=83763 width=439) (actual time=0.015..172.984 rows=115623 loops=9)
"                    Output: data.id, data.facility_id, data.attachment_id, data.facility_metric_id, data.measured_dt, data.labels, data.labels_hash, data.value_num, data.value_int, data.value_bool, data.value_text, data.value_json, data.received_dt"
                    Index Cond: ((data.facility_id = 29) AND (data.facility_metric_id = def.id))
                    Buffers: shared hit=214134 read=707010
Planning:
  Buffers: shared hit=87 read=2
Planning Time: 1.193 ms
Execution Time: 2321.874 ms
```
이 실행 계획을 토대로 어떤 과정을 거쳐서 


## 참고자료
[TypeORM Configuration](https://typeorm.io/docs/data-source/data-source-options)







